{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "import uuid\n",
    "\n",
    "from numpy import *\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "# squelch an anaconda \"bug\" and some python verbosity\n",
    "# this can move to system wide python if needed\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header = ['SPID','SA','UOM','DIR','DATE','RS','NAICS','APCT',\n",
    " '0:00',\n",
    " '0:15',\n",
    " '0:30',\n",
    " '0:45',\n",
    " '1:00',\n",
    " '1:15',\n",
    " '1:30',\n",
    " '1:45',\n",
    " '2:00',\n",
    " '2:15',\n",
    " '2:30',\n",
    " '2:45',\n",
    " '3:00',\n",
    " '3:15',\n",
    " '3:30',\n",
    " '3:45',\n",
    " '4:00',\n",
    " '4:15',\n",
    " '4:30',\n",
    " '4:45',\n",
    " '5:00',\n",
    " '5:15',\n",
    " '5:30',\n",
    " '5:45',\n",
    " '6:00',\n",
    " '6:15',\n",
    " '6:30',\n",
    " '6:45',\n",
    " '7:00',\n",
    " '7:15',\n",
    " '7:30',\n",
    " '7:45',\n",
    " '8:00',\n",
    " '8:15',\n",
    " '8:30',\n",
    " '8:45',\n",
    " '9:00',\n",
    " '9:15',\n",
    " '9:30',\n",
    " '9:45',\n",
    " '10:00',\n",
    " '10:15',\n",
    " '10:30',\n",
    " '10:45',\n",
    " '11:00',\n",
    " '11:15',\n",
    " '11:30',\n",
    " '11:45',\n",
    " '12:00',\n",
    " '12:15',\n",
    " '12:30',\n",
    " '12:45',\n",
    " '13:00',\n",
    " '13:15',\n",
    " '13:30',\n",
    " '13:45',\n",
    " '14:00',\n",
    " '14:15',\n",
    " '14:30',\n",
    " '14:45',\n",
    " '15:00',\n",
    " '15:15',\n",
    " '15:30',\n",
    " '15:45',\n",
    " '16:00',\n",
    " '16:15',\n",
    " '16:30',\n",
    " '16:45',\n",
    " '17:00',\n",
    " '17:15',\n",
    " '17:30',\n",
    " '17:45',\n",
    " '18:00',\n",
    " '18:15',\n",
    " '18:30',\n",
    " '18:45',\n",
    " '19:00',\n",
    " '19:15',\n",
    " '19:30',\n",
    " '19:45',\n",
    " '20:00',\n",
    " '20:15',\n",
    " '20:30',\n",
    " '20:45',\n",
    " '21:00',\n",
    " '21:15',\n",
    " '21:30',\n",
    " '21:45',\n",
    " '22:00',\n",
    " '22:15',\n",
    " '22:30',\n",
    " '22:45',\n",
    " '23:00',\n",
    " '23:15',\n",
    " '23:30',\n",
    " '23:45',\n",
    " 'ZIPCODE',\n",
    " 'SUBLAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "customers = pd.read_csv('../../2016/PGE/D1977_OFFICE_LBNL.csv',delimiter=',')\n",
    "# customers.drop(customers.columns[[0]], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def str2float(x):\n",
    "    try:\n",
    "        return(\"{0:.3f}\".format(float(x)))\n",
    "    except ValueError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the analyze the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CleanMeterData(df, SAID, weather_file, holidays, DREventDays):\n",
    "    df2 = df[df['SA'] == SAID].sort_index(axis=0)\n",
    "    df3 = pd.DataFrame(df2[df2.columns[8:104]].stack(),columns=['energykWh'])\n",
    "    df3.index.names = ['Date','Time']\n",
    "\n",
    "    dateindex = []\n",
    "    for datenum in range(len(df3)):\n",
    "        dateindex.append(df3.index[datenum][0].strftime('%Y-%m-%d')+' '+df3.index[datenum][1])\n",
    "\n",
    "    df3.index = pd.to_datetime(dateindex, format='%Y-%m-%d %H:%M')\n",
    "    \n",
    "    df3['power'] = df3['energykWh'].apply(lambda x: str2float(x))\n",
    "    df3[['power']] = df3[['power']].astype(float)\n",
    "    df3.power = df3.power * 4 # convert kWh to kW\n",
    "\n",
    "    df3['day'] = list(map(lambda x: x.strftime('%Y/%m/%d'),df3.index))\n",
    "    df3['time'] = list(map(lambda x: x.strftime('%H:%M'),df3.index))\n",
    "    df3['month'] = list(map(lambda x: x.strftime('%m'),df3.index))\n",
    "    df3['hour'] = list(map(lambda x: x.strftime('%H'),df3.index))\n",
    "    df3['month'] = df3.month.astype(int)\n",
    "    df3['hour'] = df3.hour.astype(int)\n",
    "    df3['weekday'] = df3.index.weekday\n",
    "    df3['holiday'] = list(map(lambda x: x.strftime('%Y-%m-%d') in holidays.day.values,df3.index))\n",
    "    df3['holiday'] = df3.holiday.astype(int)\n",
    "    df3['DREventDay'] = list(map(lambda x: x.strftime('%Y-%m-%d') in DREventDays.day.values,df3.index))\n",
    "    df3['DREventDay'] = df3.DREventDay.astype(int)\n",
    "    \n",
    "    weather = read_weather(weather_file)\n",
    "    data = pd.concat([df3,weather],axis=1,join_axes=[df3.index])\n",
    "    \n",
    "    data.fillna(method='pad')\n",
    "\n",
    "    # calculate basepower on weekdays\n",
    "    data.loc[:,'basepower'] = 0\n",
    "    data.loc[:,'peakoat'] = 0\n",
    "\n",
    "    # calculate the daily peak OAT\n",
    "    PeakOAT = data.groupby(['day'])['oat'].max()\n",
    "\n",
    "    for day in PeakOAT.index:\n",
    "        data.loc[(data['day'] == day),'peakoat'] = PeakOAT[day]\n",
    "\n",
    "    # subset the weekday and weekend power\n",
    "    df_wd = data.loc[(data['weekday'] >= 0) & (data['weekday'] <= 4) & (data['holiday'] == 0)]\n",
    "    df_wk = data.loc[(data.weekday.apply(lambda x: x in [5,6])) | (data['holiday'] == 1)]\n",
    "\n",
    "    # calculate the basepower on weekdays and weekend\n",
    "    df_wd_base = df_wd.loc[(df_wd['peakoat'] < 45)]\n",
    "    df_wd_basedaily = df_wd_base.pivot(index='time',columns='day',values='power')\n",
    "\n",
    "    for tim in df_wd_basedaily.index:\n",
    "        data.loc[(data['time'] == tim) & (data['weekday'] >= 0) & \\\n",
    "           (data['weekday'] <= 4) & (data['holiday'] == 0),'basepower'] = df_wd_basedaily.mean(axis=1)[tim]\n",
    "        data.loc[(data['time'] == tim) & (data.weekday.apply(lambda x: x in [5,6])),'basepower'] = df_wd_basedaily.mean(axis=1)[tim]\n",
    "        data.loc[(data['time'] == tim) & (data['holiday'] == 1),'basepower'] = df_wd_basedaily.mean(axis=1)[tim]\n",
    "\n",
    "    data.loc[:,'hvac'] = data.power - data.basepower\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# consider the holidays and previous DR Event days in 2015\n",
    "holidays = pd.read_csv('/Users/ryin/Dropbox/LBNL/PGE/model_input/holiday.csv', usecols=[0])\n",
    "holidays['date'] = pd.to_datetime(pd.Series(holidays['date']), format='%m/%d/%y')\n",
    "holidays['day'] = holidays.date.apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "\n",
    "DREventDays = pd.read_csv('/Users/ryin/Dropbox/LBNL/PGE/model_input/DREventDays.csv', usecols=[0])\n",
    "DREventDays['date'] = pd.to_datetime(pd.Series(DREventDays['date']), format='%m/%d/%y')\n",
    "DREventDays['day'] = DREventDays.date.apply(lambda x: x.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zc2cz(zipcode):\n",
    "    ZipCodeClimateZone = pd.read_csv('/Users/ryin/Dropbox/LBNL/PGE/model_input/BuildingClimateZonesByZIPCode.csv')\n",
    "    ClimateZone = ZipCodeClimateZone.loc[ZipCodeClimateZone['ZipCode'] == zc,'ClimateZone'].values\n",
    "    return \"{0:0=2d}\".format(int(ClimateZone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_weather(weather_file):\n",
    "    weather = pd.read_csv(weather_file,header=None)\n",
    "    weather.columns = ['Date','oat']\n",
    "    weather.index = pd.to_datetime(weather.Date, format='%m/%d/%Y %H:%M')\n",
    "    weather = weather.drop(['Date'],axis=1)\n",
    "    weather = weather.groupby(weather.index).first() # remove duplicated Index in DataFrame\n",
    "    weather = weather.asfreq('15min', method='pad') # fill missing timeseries data in DataFrame\n",
    "    return weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_utility_TOU(df, tariff, kWShed):\n",
    "    utility = []\n",
    "    utility = pd.read_csv('/Users/ryin/Dropbox/LBNL/PGE/utilityrates/'+'PGE_'+tariff+'.csv', usecols=[1])\n",
    "\n",
    "    # meter charge\n",
    "    meter_charge = float(\"{0:.2f}\".format(utility['Secondary'][0]))\n",
    "    # demand charge\n",
    "    summer_onpeak_demand = utility['Secondary'][1]\n",
    "    summer_midpeak_demand = utility['Secondary'][2]\n",
    "    summer_monthly_demand = utility['Secondary'][3]\n",
    "    winter_midpeak_demand = utility['Secondary'][4]\n",
    "    winter_monthly_demand = utility['Secondary'][5]\n",
    "\n",
    "    # energy charge\n",
    "    summer_onpeak_energy = utility['Secondary'][6]\n",
    "    summer_midpeak_energy = utility['Secondary'][7]\n",
    "    summer_offpeak_energy = utility['Secondary'][8]\n",
    "    winter_midpeak_energy = utility['Secondary'][9]\n",
    "    winter_offpeak_energy = utility['Secondary'][10]\n",
    "\n",
    "    # PDP charge and credits\n",
    "    cpp_charge = utility['Secondary'][11]\n",
    "    credits_onpeak_demand = utility['Secondary'][12]\n",
    "    credits_midpeak_demand = utility['Secondary'][13]\n",
    "\n",
    "    # add energy charge as new column in dataframe\n",
    "    try:\n",
    "        data = df['2015']\n",
    "        data['energycharge'] = 0\n",
    "\n",
    "        # weekdays in summer\n",
    "        data.loc[(data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                 (data['weekday'] < 5) & \\\n",
    "                 (data['time'] >= '00:00') & (data['time'] < '08:30'),'energycharge'] = summer_offpeak_energy\n",
    "\n",
    "        data.loc[(data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                 (data['weekday'] < 5) & \\\n",
    "                 (data['time'] >= '08:30') & (data['time'] < '12:00'),'energycharge'] = summer_midpeak_energy\n",
    "\n",
    "        data.loc[(data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                 (data['weekday'] < 5) & \\\n",
    "                 (data.time >= '12:00') & (data.time < '18:00'),'energycharge'] = summer_onpeak_energy\n",
    "\n",
    "        data.loc[(data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                 (data['weekday'] < 5) & \\\n",
    "                 (data['time'] >= '18:00') & (data['time'] < '23:00'),'energycharge'] = summer_midpeak_energy\n",
    "\n",
    "        data.loc[(data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                 (data['weekday'] < 5) & \\\n",
    "                 (data['time'] >= '23:00') & (data['time'] <= '23:45'),'energycharge'] = summer_offpeak_energy\n",
    "\n",
    "        # weekdays in winter\n",
    "        data.loc[(data.month.apply(lambda x: (x in [1,2,3,4,11,12]))) & \\\n",
    "                 (data.weekday < 5) & \\\n",
    "                 (data.time >= '00:00') & (data.time < '08:30'),'energycharge'] = winter_offpeak_energy\n",
    "\n",
    "        data.loc[(data.month.apply(lambda x: (x in [1,2,3,4,11,12]))) & \\\n",
    "                 (data.weekday < 5) & \\\n",
    "                 (data.time >= '08:30') & (data.time < '21:30'),'energycharge'] = winter_midpeak_energy\n",
    "\n",
    "        data.loc[(data.month.apply(lambda x: (x in [1,2,3,4,11,12]))) & \\\n",
    "                 (data.weekday < 5) & \\\n",
    "                 (data.time >= '21:30') & (data.time <= '23:45'),'energycharge'] = winter_offpeak_energy    \n",
    "\n",
    "        # weekend and holidays in summer and winter\n",
    "        data.loc[((data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                  (data.weekday >= 5)),'energycharge'] = summer_offpeak_energy\n",
    "\n",
    "        data.loc[((data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                  (data.holiday == 1)),'energycharge'] = summer_offpeak_energy\n",
    "\n",
    "        data.loc[((data.month.apply(lambda x: (x in [1,2,3,4,11,12]))) & \\\n",
    "                  (data.weekday >= 5)),'energycharge'] = winter_offpeak_energy\n",
    "\n",
    "        data.loc[((data.month.apply(lambda x: (x in [1,2,3,4,11,12]))) & \\\n",
    "                  (data.holiday == 1)),'energycharge'] = winter_offpeak_energy\n",
    "\n",
    "        # Calculate Capacity Reservation Level (CRL), 50% CRL\n",
    "        CRL = np.mean(data.loc[(data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                           (data.weekday < 5) & \\\n",
    "                           (data.time >= '12:00') & (data.time < '18:00'),'power'].values) * 0.5\n",
    "\n",
    "        # Calculate energy cost by multipling demand with energy charge \n",
    "        data['energycost'] = data.power * data.energycharge / 4\n",
    "\n",
    "        monthly_cost = []\n",
    "        monthly_cost = pd.DataFrame(columns = ('onpeak_demand', \\\n",
    "                                               'midpeak_demand',\\\n",
    "                                               'monthly_demand', \\\n",
    "                                               'monthly_demandcharge', \\\n",
    "                                               'monthly_onpeak_demandcharge', \\\n",
    "                                               'monthly_midpeak_demandcharge', \\\n",
    "                                               'monthly_energycharge', \\\n",
    "                                               'monthly_charge', \\\n",
    "                                               'monthly_cpp_credits',\\\n",
    "                                               'monthly_cpp_charge',\\\n",
    "                                               'monthly_CRL_charge',\\\n",
    "                                               'monthly_total_cost'))\n",
    "        for i in range(1,13,1):\n",
    "            # Monthly Demand Charges\n",
    "            if i in [1,2,3,4,11,12]:\n",
    "                midpeak_demand = max(data.loc[(data.month == i) & (data.weekday < 5) & \\\n",
    "                                (data.time >= '08:30') & (data.time < '21:30'),'power'].values)\n",
    "                monthly_demand = max(data.loc[(data.month == i),'power'].values)\n",
    "                onpeak_demand = 0\n",
    "                \n",
    "                monthly_energycharge = data.loc[(data.month == i),'energycost'].sum()\n",
    "                monthly_demandcharge = monthly_demand * winter_monthly_demand  \n",
    "                monthly_onpeak_demandcharge = 0\n",
    "                monthly_midpeak_demandcharge = midpeak_demand * winter_midpeak_demand \n",
    "                monthly_charge = monthly_energycharge + monthly_demandcharge + monthly_onpeak_demandcharge + monthly_midpeak_demandcharge\n",
    "            elif i in [5,6,7,8,9,10]:\n",
    "                onpeak_demand = max(data.loc[(data.month == i) & (data.weekday < 5) & \\\n",
    "                                (data.time >= '12:00') & (data.time < '18:00'),'power'].values)\n",
    "                onpeak_energycost = sum(data.loc[(data.month == i) & (data.weekday < 5) & \\\n",
    "                                    (data.time >= '12:00') & (data.time < '18:00'),'power'].values)                    \n",
    "                midpeak_demand1 = max(data.loc[(data.month == i) & (data.weekday < 5) & \\\n",
    "                                    (data.time >= '18:00') & (data.time < '21:30'),'power'].values)\n",
    "                midpeak_demand2 = max(data.loc[(data.month == i) & (data.weekday < 5) & \\\n",
    "                                    (data.time >= '08:30') & (data.time < '12:00'),'power'].values)   \n",
    "                midpeak_demand = max(midpeak_demand1,midpeak_demand2)                                         \n",
    "                monthly_demand = max(data.loc[(data.month == i),'power'].values)\n",
    "                \n",
    "                monthly_energycharge = data.loc[(data.month == i),'energycost'].sum()\n",
    "                monthly_demandcharge = monthly_demand * summer_monthly_demand\n",
    "                monthly_onpeak_demandcharge = onpeak_demand * summer_onpeak_demand  \n",
    "                monthly_midpeak_demandcharge = midpeak_demand * summer_midpeak_demand \n",
    "                monthly_charge = monthly_energycharge + monthly_demandcharge + monthly_onpeak_demandcharge + monthly_midpeak_demandcharge\n",
    "            else:\n",
    "                pass\n",
    "            # PDP Credits\n",
    "            monthly_cpp_credits = 0\n",
    "            monthly_cpp_charge = 0\n",
    "            monthly_CRL_charge = 0\n",
    "\n",
    "            # monthly cost\n",
    "            monthly_total_cost = monthly_charge + monthly_cpp_credits + monthly_CRL_charge\n",
    "\n",
    "            # Summary of Energy and Demand Charges\n",
    "            monthly_cost.loc[i] = [onpeak_demand,\\\n",
    "                                   midpeak_demand,\\\n",
    "                                   monthly_demand, \\\n",
    "                                   monthly_demandcharge, \\\n",
    "                                   monthly_onpeak_demandcharge, \\\n",
    "                                   monthly_midpeak_demandcharge, \\\n",
    "                                   monthly_energycharge, \\\n",
    "                                   monthly_charge, \\\n",
    "                                   monthly_cpp_credits,\\\n",
    "                                   monthly_cpp_charge,\\\n",
    "                                   monthly_CRL_charge,\\\n",
    "                                   monthly_total_cost]\n",
    "        annualcost = monthly_cost.monthly_total_cost.sum()\n",
    "    except ValueError:\n",
    "        print('MeterData is Not Available')\n",
    "        annualcost = 0\n",
    "    monthly_cost.to_csv('/Users/ryin/Dropbox/LBNL/PGE/utilitycost_PGE_'+tariff+'.csv')\n",
    "\n",
    "    return annualcost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_utility_PDP(df, tariff, kWShed):\n",
    "    utility = []\n",
    "    utility = pd.read_csv('/Users/ryin/Dropbox/LBNL/PGE/utilityrates/'+'PGE_'+tariff+'.csv', usecols=[1])\n",
    "\n",
    "    # meter charge\n",
    "    meter_charge = float(\"{0:.2f}\".format(utility['Secondary'][0]))\n",
    "    # demand charge\n",
    "    summer_onpeak_demand = utility['Secondary'][1]\n",
    "    summer_midpeak_demand = utility['Secondary'][2]\n",
    "    summer_monthly_demand = utility['Secondary'][3]\n",
    "    winter_midpeak_demand = utility['Secondary'][4]\n",
    "    winter_monthly_demand = utility['Secondary'][5]\n",
    "\n",
    "    # energy charge\n",
    "    summer_onpeak_energy = utility['Secondary'][6]\n",
    "    summer_midpeak_energy = utility['Secondary'][7]\n",
    "    summer_offpeak_energy = utility['Secondary'][8]\n",
    "    winter_midpeak_energy = utility['Secondary'][9]\n",
    "    winter_offpeak_energy = utility['Secondary'][10]\n",
    "\n",
    "    # PDP charge and credits\n",
    "    cpp_charge = utility['Secondary'][11]\n",
    "    credits_onpeak_demand = utility['Secondary'][12]\n",
    "    credits_midpeak_demand = utility['Secondary'][13]\n",
    "    \n",
    "    \n",
    "    # add energy charge as new column in dataframe\n",
    "    try:\n",
    "        data = df['2015']\n",
    "        data['energycharge'] = 0\n",
    "\n",
    "        # weekdays in summer\n",
    "        data.loc[(data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                 (data.weekday < 5) & \\\n",
    "                 (data.time >= '00:00') & (data.time < '08:30'),'energycharge'] = summer_offpeak_energy\n",
    "\n",
    "        data.loc[(data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                 (data.weekday < 5) & \\\n",
    "                 (data.time >= '08:30') & (data.time < '12:00'),'energycharge'] = summer_midpeak_energy\n",
    "\n",
    "        data.loc[(data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                 (data.weekday < 5) & \\\n",
    "                 (data.time >= '12:00') & (data.time < '18:00'),'energycharge'] = summer_onpeak_energy\n",
    "\n",
    "        data.loc[(data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                 (data.weekday < 5) & \\\n",
    "                 (data.time >= '18:00') & (data.time < '23:00'),'energycharge'] = summer_midpeak_energy\n",
    "\n",
    "        data.loc[(data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                 (data.weekday < 5) & \\\n",
    "                 (data.time >= '23:00') & (data.time <= '23:45'),'energycharge'] = summer_offpeak_energy\n",
    "        # add the PDP charge during the DR Event Hours\n",
    "        data.loc[(data.DREventDay == 1) & \\\n",
    "                 (data.time >= '14:00') & (data.time < '18:00'),'energycharge'] = summer_onpeak_energy + cpp_charge\n",
    "        # weekdays in winter\n",
    "        data.loc[(data.month.apply(lambda x: (x in [1,2,3,4,11,12]))) & \\\n",
    "                 (data.weekday < 5) & \\\n",
    "                 (data.time >= '00:00') & (data.time < '08:30'),'energycharge'] = winter_offpeak_energy\n",
    "\n",
    "        data.loc[(data.month.apply(lambda x: (x in [1,2,3,4,11,12]))) & \\\n",
    "                 (data.weekday < 5) & \\\n",
    "                 (data.time >= '08:30') & (data.time < '21:30'),'energycharge'] = winter_midpeak_energy\n",
    "\n",
    "        data.loc[(data.month.apply(lambda x: (x in [1,2,3,4,11,12]))) & \\\n",
    "                 (data.weekday < 5) & \\\n",
    "                 (data.time >= '21:30') & (data.time <= '23:45'),'energycharge'] = winter_offpeak_energy    \n",
    "\n",
    "        # weekend and holidays in summer and winter\n",
    "        data.loc[((data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                  (data.weekday >= 5)),'energycharge'] = summer_offpeak_energy\n",
    "\n",
    "        data.loc[((data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                  (data.holiday == 1)),'energycharge'] = summer_offpeak_energy\n",
    "\n",
    "        data.loc[((data.month.apply(lambda x: (x in [1,2,3,4,11,12]))) & \\\n",
    "                  (data.weekday >= 5)),'energycharge'] = winter_offpeak_energy\n",
    "\n",
    "        data.loc[((data.month.apply(lambda x: (x in [1,2,3,4,11,12]))) & \\\n",
    "                  (data.holiday == 1)),'energycharge'] = winter_offpeak_energy\n",
    "\n",
    "        # Calculate Capacity Reservation Level (CRL), 50% CRL\n",
    "        CRL = np.mean(data.loc[(data.month.apply(lambda x: (x in [5,6,7,8,9,10]))) & \\\n",
    "                           (data.weekday < 5) & \\\n",
    "                           (data.time >= '12:00') & (data.time < '18:00'),'power'].values) * 0.5\n",
    "        data.loc[(data.DREventDay == 1) & \\\n",
    "                 (data.time >= '14:00') & (data.time < '18:00'),'power'] = data.loc[(data.DREventDay == 1) & \\\n",
    "                 (data.time >= '14:00') & (data.time < '18:00'),'power'].values - kWShed\n",
    "\n",
    "        # Calculate energy cost by multipling demand with energy charge \n",
    "        data['energycost'] = data.power * data.energycharge / 4\n",
    "\n",
    "        monthly_cost = []\n",
    "        monthly_cost = pd.DataFrame(columns = ('onpeak_demand', \\\n",
    "                                               'midpeak_demand',\\\n",
    "                                               'monthly_demand', \\\n",
    "                                               'monthly_demandcharge', \\\n",
    "                                               'monthly_onpeak_demandcharge', \\\n",
    "                                               'monthly_midpeak_demandcharge', \\\n",
    "                                               'monthly_energycharge', \\\n",
    "                                               'monthly_charge', \\\n",
    "                                               'monthly_cpp_credits',\\\n",
    "                                               'monthly_cpp_charge',\\\n",
    "                                               'monthly_CRL_charge',\\\n",
    "                                               'monthly_total_cost'))\n",
    "        for i in range(1,13,1):\n",
    "            # Monthly Demand Charges\n",
    "            if i in [1,2,3,4,11,12]:\n",
    "                midpeak_demand = max(data.loc[(data.month == i) & (data.weekday < 5) & \\\n",
    "                                (data.time >= '08:30') & (data.time < '21:30'),'power'].values)\n",
    "\n",
    "                monthly_demand = max(data.loc[data['month'] == i,'power'].values)\n",
    "                onpeak_demand = 0\n",
    "                \n",
    "                monthly_energycharge = sum(data.loc[data['month'] == i,'energycost'].values)\n",
    "                monthly_demandcharge = monthly_demand * winter_monthly_demand  \n",
    "                monthly_onpeak_demandcharge = 0\n",
    "                monthly_midpeak_demandcharge = midpeak_demand * winter_midpeak_demand \n",
    "                monthly_charge = monthly_energycharge + monthly_demandcharge + monthly_onpeak_demandcharge + monthly_midpeak_demandcharge\n",
    "                monthly_cpp_credits = 0\n",
    "                monthly_cpp_charge = 0\n",
    "                monthly_CRL_charge = 0\n",
    "            elif i in [5,6,7,8,9,10]:\n",
    "                onpeak_demand = max(data.loc[(data.month == i) & (data.weekday < 5) & \\\n",
    "                                (data.time >= '12:00') & (data.time < '18:00'),'power'].values)\n",
    "                onpeak_energycost = sum(data.loc[(data.month == i) & (data.weekday < 5) & \\\n",
    "                                    (data.time >= '12:00') & (data.time < '18:00'),'power'].values)                    \n",
    "                midpeak_demand1 = max(data.loc[(data.month == i) & (data.weekday < 5) & \\\n",
    "                                    (data.time >= '18:00') & (data.time < '21:30'),'power'].values)\n",
    "                midpeak_demand2 = max(data.loc[(data.month == i) & (data.weekday < 5) & \\\n",
    "                                    (data.time >= '08:30') & (data.time < '12:00'),'power'].values)   \n",
    "                midpeak_demand = max(midpeak_demand1,midpeak_demand2)                                         \n",
    "                monthly_demand = max(data.loc[(data.month == i),'power'].values)\n",
    "                \n",
    "                monthly_energycharge = sum(data.loc[data['month'] == i,'energycost'].values)\n",
    "                monthly_demandcharge = monthly_demand * summer_monthly_demand\n",
    "                monthly_onpeak_demandcharge = onpeak_demand * (summer_onpeak_demand + credits_onpeak_demand)  \n",
    "                monthly_midpeak_demandcharge = midpeak_demand * (summer_midpeak_demand + credits_midpeak_demand)\n",
    "                monthly_charge = monthly_energycharge + monthly_demandcharge + monthly_onpeak_demandcharge + monthly_midpeak_demandcharge\n",
    "\n",
    "            # PDP Credits\n",
    "                monthly_cpp_credits = onpeak_demand * credits_onpeak_demand + midpeak_demand * credits_midpeak_demand\n",
    "                monthly_cpp_charge = sum(data.loc[(data.month == i) & (data.DREventDay == 1) & \\\n",
    "                                        (data.time >= '14:00') & (data.time < '18:00'),'energycost'].values)\n",
    "                monthly_CRL_charge = 0\n",
    "            else:\n",
    "                pass\n",
    "            # monthly cost\n",
    "            monthly_total_cost = monthly_charge + monthly_cpp_credits + monthly_CRL_charge\n",
    "\n",
    "            # Summary of Energy and Demand Charges\n",
    "            monthly_cost.loc[i] = [onpeak_demand, midpeak_demand, monthly_demand, monthly_demandcharge, \n",
    "                                   monthly_onpeak_demandcharge, monthly_midpeak_demandcharge, \n",
    "                                   monthly_energycharge, monthly_charge, monthly_cpp_credits,\n",
    "                                   monthly_cpp_charge, monthly_CRL_charge, monthly_total_cost]\n",
    "        annualcost = monthly_cost.monthly_total_cost.sum()\n",
    "    except ValueError:\n",
    "        print('MeterData is Not Available')\n",
    "        annualcost = 0\n",
    "    monthly_cost.to_csv('/Users/ryin/Dropbox/LBNL/PGE/utilitycost_PGE_'+tariff+'.csv')\n",
    "#     data.to_csv('/Users/ryin/Dropbox/LBNL/PGE/utilitycost_PGE_Meter'+tariff+'.csv')\n",
    "\n",
    "    return annualcost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate all the basic metric from meter data and weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateCustMetrics(df, customers, SAID, cz):\n",
    "    \n",
    "    df_wd = df.loc[(df['weekday'] >= 0) & (df['weekday'] <= 4) & (df['holiday'] == 0)]\n",
    "    df_cssb = df_wd.loc[(df_wd['month'] >= 5) & (df_wd['month'] <= 10),['power','hour','time','oat']]\n",
    "    CSSB = df_cssb.groupby(['time'])['power'].mean()\n",
    "\n",
    "    hotDays = df_wd.groupby(['day'])['oat'].max().sort_values(ascending=False)[0:10]\n",
    "    hotDaysPower = df.loc[saidData['day'].isin(hotDays.index),['power', 'oat','time','day']]\n",
    "    hotDaysHVAC = df.loc[saidData['day'].isin(hotDays.index),['hvac', 'oat','time','day']]\n",
    "\n",
    "    custHVAC = hotDaysHVAC.pivot(index='time',columns='day',values='hvac')\n",
    "    custHVAC.columns = ['hotDayHVAC0','hotDayHVAC1','hotDayHVAC2','hotDayHVAC3','hotDayHVAC4',\n",
    "                        'hotDayHVAC5','hotDayHVAC6','hotDayHVAC7','hotDayHVAC8','hotDayHVAC9']\n",
    "    custHVAC['hotDayHVAC'] = hotDaysHVAC.groupby(['time'])['hvac'].mean()\n",
    "\n",
    "    custMetrics = hotDaysPower.pivot(index='time',columns='day',values='power')\n",
    "    custMetrics.columns = ['hotDay0','hotDay1','hotDay2','hotDay3','hotDay4',\n",
    "                           'hotDay5','hotDay6','hotDay7','hotDay8','hotDay9']\n",
    "    custMetrics['cssb'] = df_cssb.groupby(['time'])['power'].mean()\n",
    "    custMetrics['LoadVariability_kW'] = df_cssb.groupby(['time'])['power'].std()\n",
    "    custMetrics['LoadVariability_Pct'] = custMetrics['LoadVariability_kW'] / custMetrics['cssb'] \n",
    "    custMetrics['HotDaysLoadVariability_kW'] = hotDaysPower.groupby(['time'])['power'].std()\n",
    "    custMetrics['HotDaysLoadVariability_Pct'] = custMetrics['HotDaysLoadVariability_kW'] / hotDaysPower.groupby(['time'])['power'].mean() \n",
    "    custMetrics['hotDay'] = hotDaysPower.groupby(['time'])['power'].mean()\n",
    "    custMetrics['peakDay'] = df.loc[df['day'] == df.power.idxmax().strftime('%Y/%m/%d'),'power'].values\n",
    "\n",
    "    DR_Equations = pd.read_csv('/Users/ryin/Dropbox/LBNL/PGE/DREquations/DREquations_CZ'+str(cz)+'.csv')\n",
    "    DR_Equations.index = DR_Equations.DR_Controls\n",
    "\n",
    "    custOAT = hotDaysPower.pivot(index='time',columns='day',values='oat')\n",
    "    custOAT.columns = ['hotDayOAT0','hotDayOAT1','hotDayOAT2','hotDayOAT3','hotDayOAT4','hotDayOAT5','hotDayOAT6',\n",
    "                       'hotDayOAT7','hotDayOAT8','hotDayOAT9']\n",
    "    custOAT['cssb_oat'] = df_cssb.groupby(['time'])['oat'].mean()\n",
    "    custOAT['hotDay_oat'] = hotDaysPower.groupby(['time'])['oat'].mean()\n",
    "    custOAT['peakDay_oat'] = df.loc[df['day'] == df.power.idxmax().strftime('%Y/%m/%d'),'oat'].values\n",
    "    custOAT['hour'] = df.loc[df['day'] == df.power.idxmax().strftime('%Y/%m/%d'),'hour'].values\n",
    "    custOAT['NoPrecool_Reset2F_alpha'] = np.nan\n",
    "    custOAT['NoPrecool_Reset2F_beta'] = np.nan\n",
    "    custOAT['NoPrecool_Reset4F_alpha'] = np.nan\n",
    "    custOAT['NoPrecool_Reset4F_beta'] = np.nan\n",
    "    custOAT['NoPrecool_Reset6F_alpha'] = np.nan\n",
    "    custOAT['NoPrecool_Reset6F_beta'] = np.nan\n",
    "    custOAT['Precool2F_Reset2F_alpha'] = np.nan\n",
    "    custOAT['Precool2F_Reset2F_beta'] = np.nan\n",
    "    custOAT['Precool2F_Reset4F_alpha'] = np.nan\n",
    "    custOAT['Precool2F_Reset4F_beta'] = np.nan\n",
    "    custOAT['Precool2F_Reset6F_alpha'] = np.nan\n",
    "    custOAT['Precool2F_Reset6F_beta'] = np.nan\n",
    "\n",
    "    for hour in range(14,18):\n",
    "        custOAT.loc[custOAT['hour'] == hour, ['NoPrecool_Reset2F_alpha','NoPrecool_Reset2F_beta']] = \\\n",
    "            DR_Equations.loc[(DR_Equations['hour'] == hour) & (DR_Equations['precool'] == 0) & (DR_Equations['reset'] == 2), ['alpha_2','beta_2']].values\n",
    "        custOAT.loc[custOAT['hour'] == hour, ['NoPrecool_Reset4F_alpha','NoPrecool_Reset4F_beta']] = \\\n",
    "            DR_Equations.loc[(DR_Equations['hour'] == hour) & (DR_Equations['precool'] == 0) & (DR_Equations['reset'] == 4), ['alpha_2','beta_2']].values\n",
    "        custOAT.loc[custOAT['hour'] == hour, ['NoPrecool_Reset6F_alpha','NoPrecool_Reset6F_beta']] = \\\n",
    "            DR_Equations.loc[(DR_Equations['hour'] == hour) & (DR_Equations['precool'] == 0) & (DR_Equations['reset'] == 6), ['alpha_2','beta_2']].values\n",
    "\n",
    "        custOAT.loc[custOAT['hour'] == hour, ['Precool2F_Reset2F_alpha','Precool2F_Reset2F_beta']] = \\\n",
    "            DR_Equations.loc[(DR_Equations['hour'] == hour) & (DR_Equations['precool'] == 2) & (DR_Equations['reset'] == 2), ['alpha_2','beta_2']].values\n",
    "        custOAT.loc[custOAT['hour'] == hour, ['Precool2F_Reset4F_alpha','Precool2F_Reset4F_beta']] = \\\n",
    "            DR_Equations.loc[(DR_Equations['hour'] == hour) & (DR_Equations['precool'] == 2) & (DR_Equations['reset'] == 4), ['alpha_2','beta_2']].values\n",
    "        custOAT.loc[custOAT['hour'] == hour, ['Precool2F_Reset6F_alpha','Precool2F_Reset6F_beta']] = \\\n",
    "            DR_Equations.loc[(DR_Equations['hour'] == hour) & (DR_Equations['precool'] == 2) & (DR_Equations['reset'] == 6), ['alpha_2','beta_2']].values\n",
    "\n",
    "    result = pd.concat([custMetrics, custOAT, custHVAC], axis=1)\n",
    "\n",
    "    usrInput = customers[customers['sa_id'] == SAID]\n",
    "    usrOutput = pd.DataFrame()\n",
    "\n",
    "    usrOutput['SAID'] = usrInput.sa_id\n",
    "    usrOutput['UUID'] = uuid.uuid4()\n",
    "    usrOutput.index = usrOutput['UUID']\n",
    "    usrOutput['Peak_kW'] = df.power.max()\n",
    "    usrOutput['Peak_kW_timestamp'] = df.power.idxmax()\n",
    "    \n",
    "    usrOutput['NAICS'] = usrInput.sa_naics_cd.values\n",
    "    usrOutput['NAICS_desc'] = usrInput.naics_desc.values\n",
    "    usrOutput['cty'] = usrInput.cty_nm.values\n",
    "    usrOutput['ZIPCODE'] = usrInput.zip_5_dgt.values\n",
    "    usrOutput['SUBLAP'] = 'SLAP_PGSN-APND'\n",
    "    usrOutput['PGE_CZ'] = cz\n",
    "    usrOutput['CEC_CZ'] = cz\n",
    "    usrOutput['AMP'] = usrInput.AMP.values\n",
    "    usrOutput['PDP'] = usrInput.PDP.values\n",
    "    usrOutput['DBP'] = usrInput.DBP.values\n",
    "    usrOutput['CBP'] = usrInput.CBP.values\n",
    "    \n",
    "#     # Peak Day\n",
    "#     usrOutput['DR_Capacity_Precool0F_Reset2F'] = np.mean(result.peakDay * (result.NoPrecool_Reset2F_beta + result.peakDay_oat * result.NoPrecool_Reset2F_alpha)/100)\n",
    "#     usrOutput['DR_Capacity_Precool0F_Reset4F'] = np.mean(result.peakDay * (result.NoPrecool_Reset4F_beta + result.peakDay_oat * result.NoPrecool_Reset4F_alpha)/100)\n",
    "#     usrOutput['DR_Capacity_Precool0F_Reset6F'] = np.mean(result.peakDay * (result.NoPrecool_Reset6F_beta + result.peakDay_oat * result.NoPrecool_Reset6F_alpha)/100)\n",
    "#     usrOutput['DR_Capacity_Precool2F_Reset2F'] = np.mean(result.peakDay * (result.Precool2F_Reset2F_beta + result.peakDay_oat * result.Precool2F_Reset2F_alpha)/100)\n",
    "#     usrOutput['DR_Capacity_Precool2F_Reset4F'] = np.mean(result.peakDay * (result.Precool2F_Reset4F_beta + result.peakDay_oat * result.Precool2F_Reset4F_alpha)/100)\n",
    "#     usrOutput['DR_Capacity_Precool2F_Reset6F'] = np.mean(result.peakDay * (result.Precool2F_Reset6F_beta + result.peakDay_oat * result.Precool2F_Reset6F_alpha)/100)\n",
    "    # Hot Day\n",
    "    usrOutput['DR_Capacity_Precool0F_Reset2F'] = np.mean(result.hotDay * (result.NoPrecool_Reset2F_beta + result.hotDay_oat * result.NoPrecool_Reset2F_alpha)/100)\n",
    "    usrOutput['DR_Capacity_Precool0F_Reset4F'] = np.mean(result.hotDay * (result.NoPrecool_Reset4F_beta + result.hotDay_oat * result.NoPrecool_Reset4F_alpha)/100)\n",
    "    usrOutput['DR_Capacity_Precool0F_Reset6F'] = np.mean(result.hotDay * (result.NoPrecool_Reset6F_beta + result.hotDay_oat * result.NoPrecool_Reset6F_alpha)/100)\n",
    "    usrOutput['DR_Capacity_Precool2F_Reset2F'] = np.mean(result.hotDay * (result.Precool2F_Reset2F_beta + result.hotDay_oat * result.Precool2F_Reset2F_alpha)/100)\n",
    "    usrOutput['DR_Capacity_Precool2F_Reset4F'] = np.mean(result.hotDay * (result.Precool2F_Reset4F_beta + result.hotDay_oat * result.Precool2F_Reset4F_alpha)/100)\n",
    "    usrOutput['DR_Capacity_Precool2F_Reset6F'] = np.mean(result.hotDay * (result.Precool2F_Reset6F_beta + result.hotDay_oat * result.Precool2F_Reset6F_alpha)/100)\n",
    "\n",
    "    usrOutput['DR_Capacity_CycleOnOff_30Pct'] = np.mean(result['14:00':'17:45'].hotDayHVAC) * 0.3\n",
    "    usrOutput['DR_Capacity_CycleOnOff_50Pct'] = np.mean(result['14:00':'17:45'].hotDayHVAC) * 0.5\n",
    "    usrOutput['DR_Capacity_CycleOnOff_100Pct'] = np.mean(result['14:00':'17:45'].hotDayHVAC) * 1.0\n",
    "    usrOutput['HVAC_Building_Ratio'] = usrOutput['DR_Capacity_CycleOnOff_100Pct'] / result.hotDay.max()\n",
    "    usrOutput['CycleShed_Building_Ratio'] = usrOutput['DR_Capacity_CycleOnOff_50Pct'] / result.hotDay.max()\n",
    "    usrOutput['ResetShed_Building_Ratio'] = usrOutput['DR_Capacity_Precool2F_Reset4F'] / result.hotDay.max()\n",
    "    \n",
    "    usrOutput['LoadVariability_kW'] = np.mean(result['14:00':'17:45'].LoadVariability_kW)\n",
    "    usrOutput['LoadVariability_Pct'] = np.mean(result['14:00':'17:45'].LoadVariability_Pct)\n",
    "    usrOutput['HotDaysLoadVariability_kW'] = np.mean(result['14:00':'17:45'].HotDaysLoadVariability_kW)\n",
    "    usrOutput['HotDaysLoadVariability_Pct'] = np.mean(result['14:00':'17:45'].HotDaysLoadVariability_Pct)\n",
    "    # Calculate the Annual Utility Bill base on 2015 Meter Data\n",
    "    kWshed = usrOutput['DR_Capacity_CycleOnOff_50Pct'].values\n",
    "    if df.power.max() < 75:\n",
    "        usrOutput['CustSize'] = 'Small'\n",
    "        usrOutput['Tariff'] = 'A-1'\n",
    "        usrOutput['TOU_UtilityCost'] = calculate_utility_TOU(df,'A-1',0)\n",
    "        usrOutput['PDP_UtilityCost_NoADR'] = calculate_utility_PDP(df,'A-1_PDP',0)\n",
    "        usrOutput['PDP_UtilityCost_ADR'] = calculate_utility_PDP(df,'A-1_PDP',kWshed)\n",
    "\n",
    "    elif (df.power.max() >= 75) & (df.power.max() < 200):\n",
    "        usrOutput['CustSize'] = 'Small/Medium'\n",
    "        usrOutput['Tariff'] = 'A-6'\n",
    "        usrOutput['TOU_UtilityCost'] = calculate_utility_TOU(df,'A-6',0)\n",
    "        usrOutput['PDP_UtilityCost_NoADR'] = calculate_utility_PDP(df,'A-6_PDP',0)\n",
    "        usrOutput['PDP_UtilityCost_ADR'] = calculate_utility_PDP(df,'A-6_PDP',kWshed)\n",
    "\n",
    "    elif (df.power.max() >= 200) & (df.power.max() < 500):\n",
    "        usrOutput['CustSize'] = 'Medium'\n",
    "        usrOutput['Tariff'] = 'A-10'\n",
    "        usrOutput['TOU_UtilityCost'] = calculate_utility_TOU(df,'A-10',0)\n",
    "        usrOutput['PDP_UtilityCost_NoADR'] = calculate_utility_PDP(df,'A-10_PDP',0)\n",
    "        usrOutput['PDP_UtilityCost_ADR'] = calculate_utility_PDP(df,'A-10_PDP',kWshed)\n",
    "\n",
    "    elif df.power.max() >= 500:\n",
    "        usrOutput['CustSize'] = 'Large'\n",
    "        usrOutput['Tariff'] = 'E-19'\n",
    "        usrOutput['TOU_UtilityCost'] = calculate_utility_TOU(df,'E-19',0)\n",
    "        usrOutput['PDP_UtilityCost_NoADR'] = calculate_utility_PDP(df,'E-19_PDP',0)\n",
    "        usrOutput['PDP_UtilityCost_ADR'] = calculate_utility_PDP(df,'E-19_PDP',kWshed)\n",
    "    \n",
    "    usrOutput['PDP_TOU_Ratio'] = usrOutput['PDP_UtilityCost_NoADR'] / usrOutput['TOU_UtilityCost']\n",
    "    usrOutput['TOU2PDP_Benefit'] = usrOutput['TOU_UtilityCost'] - usrOutput['PDP_UtilityCost_NoADR']\n",
    "    usrOutput['TOU2PDP_ADR_Benefit'] = usrOutput['TOU_UtilityCost'] - usrOutput['PDP_UtilityCost_ADR']\n",
    "    usrOutput['PDP_ADR_Benefit'] = usrOutput['PDP_UtilityCost_NoADR'] - usrOutput['PDP_UtilityCost_ADR']\n",
    "    usrOutput['PDP_ADR_Benefit_Pct'] = usrOutput['PDP_ADR_Benefit'] / usrOutput['PDP_UtilityCost_NoADR']\n",
    "    \n",
    "    return result, usrOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ZipCodeGroup = pd.read_csv('/Users/ryin/Dropbox/LBNL/PGE/ADRGEOOfficeZips.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryin/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/ryin/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/ryin/anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/ryin/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/ryin/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/ryin/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer 838288097.0 is Completed.\n",
      "Customer 1605680066.0 is Completed.\n",
      "Customer 2041448326.0 is Completed.\n",
      "Customer 398583910.0 is Completed.\n",
      "Customer 1152913159.0 is Completed.\n",
      "Customer 2051150602.0 is Completed.\n",
      "Customer 1659186381.0 is Completed.\n",
      "MeterData is Not Available\n",
      "MeterData is Not Available\n",
      "MeterData is Not Available\n",
      "Customer 1556177005.0 is Completed.\n",
      "MeterData is Not Available\n",
      "MeterData is Not Available\n",
      "MeterData is Not Available\n",
      "Customer 1670765005.0 is Completed.\n",
      "Customer 891901840.0 is Completed.\n",
      "Customer 1627410353.0 is Completed.\n",
      "Customer 48035508.0 is Completed.\n",
      "Customer 1738264661.0 is Completed.\n",
      "Customer 1502410805.0 is Completed.\n",
      "Customer 729786169.0 is Completed.\n",
      "Customer 323154585.0 is Completed.\n",
      "Customer 1868800378.0 is Completed.\n",
      "Customer 1856089211.0 is Completed.\n",
      "Customer 60120025.0 is Completed.\n",
      "Customer 1462405501.0 is Completed.\n",
      "Customer 2117937756.0 is Completed.\n"
     ]
    }
   ],
   "source": [
    "for zc in ZipCodeGroup[ZipCodeGroup['City']=='Stockton']['Zip5'][0:1]:\n",
    "    df = pd.read_csv('/Users/ryin/Dropbox/LBNL/PGE/stockton/'+str(zc)+'.csv',header=None)\n",
    "    df.drop(df.columns[[0]], inplace=True, axis=1)\n",
    "    df.columns = header\n",
    "\n",
    "    df.DATE = pd.to_datetime(df.DATE, format='%m/%d/%Y')\n",
    "    df.index = pd.to_datetime(df.DATE, format='%m/%d/%Y')\n",
    "    \n",
    "    cz = zc2cz(zc)  # convert ZipCode to CEC Climate Zone\n",
    "    with open('/Users/ryin/Dropbox/LBNL/PGE/stockton/CustSummary_'+str(zc)+'.csv','w',newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile,delimiter=',')\n",
    "        csvheader = ['UUID','SAID','UUID','Peak_kW','Peak_kW_timestamp','NAICS',\n",
    "                     'NAICS_desc','cty','ZIPCODE','SUBLAP','PGE_CZ','CEC_CZ','AMP','PDP','DBP','CBP',\n",
    "                     'DR_Capacity_Precool0F_Reset2F','DR_Capacity_Precool0F_Reset4F','DR_Capacity_Precool0F_Reset6F',\n",
    "                     'DR_Capacity_Precool2F_Reset2F','DR_Capacity_Precool2F_Reset4F','DR_Capacity_Precool2F_Reset6F',\n",
    "                     'DR_Capacity_CycleOnOff_30Pct','DR_Capacity_CycleOnOff_50Pct','DR_Capacity_CycleOnOff_100Pct',\n",
    "                     'HVAC_Building_Ratio','CycleShed_Building_Ratio','ResetShed_Building_Ratio','LoadVariability_kW',\n",
    "                     'LoadVariability_PCT','HotDaysLoadVariability_kW',\n",
    "                     'HotDaysLoadVariability_PCT','CustSize','Tariff','TOU_UtilityCost','PDP_UtilityCost_NoADR',\n",
    "                     'PDP_UtilityCost_ADR','PDP_TOU_Ratio','TOU2PDP_Benefit','TOU2PDP_ADR_Benefit','PDP_ADR_Benefit',\n",
    "                     'PDP_ADR_Benefit_Pct']\n",
    "        writer.writerow(csvheader)\n",
    "\n",
    "    for SAID in set(df.SA):\n",
    "        weatherInput = '/Users/ryin/Dropbox/LBNL/PGE/stockton/stockon/KCASTOCK9.temperatureinterpolated.csv'\n",
    "        saidData = CleanMeterData(df, SAID, weatherInput, holidays, DREventDays)\n",
    "        metrics = pd.DataFrame()\n",
    "        custSummary = pd.DataFrame()\n",
    "        metrics, custSummary = calculateCustMetrics(saidData, customers, SAID, cz)\n",
    "        metrics.to_csv('/Users/ryin/Dropbox/LBNL/PGE/stockton/CustMetrics_'+str(zc)+'.csv',mode='w',sep=',',header=True)\n",
    "        custSummary.to_csv('/Users/ryin/Dropbox/LBNL/PGE/stockton/CustSummary_'+str(zc)+'.csv',mode='a',sep=',',header=False)\n",
    "        print('Customer ' + str(SAID)+' is Completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
